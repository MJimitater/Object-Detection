{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "From Kaggle-Competition \"Dogs vs. Cats\", a data set of 12500 dog images and 12500 cat images provided.\n",
    "The goal is to build a classifier, that can predict if either a dog (=1) or a cat (=0) is in the image.\n",
    "For the sake of running at low computational cost, we will only train the model on 1000 dog images and 1000 cat images.\n",
    "Plus, we will only use 400 images of each class to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nFound 2000 images belonging to 2 classes.\nFound 800 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "#This is to import our images to keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#specify, where\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "# set dimensions of images to 100x100\n",
    "img_width, img_height = 100, 100\n",
    "#total training images is 2000, namly 1000 dog images and 1000 cat images:\n",
    "nb_train_samples = 2000\n",
    "#total validation images is 800\n",
    "#the validation images are only to evaluate the model and calculate the loss\n",
    "nb_validation_samples = 800\n",
    "#set epochs to 20: complete data set is run through 20 times\n",
    "#too few epochs means bad accuracy\n",
    "#too many epochs means overfitting and great computational cost\n",
    "epochs = 20\n",
    "#set batch_size to 20: gradients will be upgraded everytime after 20 images\n",
    "batch_size = 20\n",
    "\n",
    "#rescale train images: pixel values are between [0,255], rescale them\n",
    "#between [0,1] for faster convergence\n",
    "train_datagen = ImageDataGenerator( rescale = 1. / 255 )\n",
    "\n",
    "#rescale test images accordingly\n",
    "test_datagen = ImageDataGenerator( rescale = 1. / 255 )\n",
    "\n",
    "#load training images from directory:\n",
    "#subfolders named \"dogs\" and \"cats\" will be taken as labels\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "#validation data we will need to evaluate the loss and the model metrics after each epoch\n",
    "#this data will NOT be trained\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these imports are needed to build our Convolutional Neural Network (CNN)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "#Sequential() will configure the model for training    \n",
    "model = Sequential()\n",
    "\n",
    "#First: Input image (100,100,3) for (width, height, channels)\n",
    "#and connect input layer with 2D convolutional layer (this is needed for images);\n",
    "#choose 32 filters and a kernel size of 3x3.\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width,img_height,3)))\n",
    "#choose rectified linear unit as activation function;\n",
    "#most of the time this is industry standard\n",
    "model.add(Activation('relu'))\n",
    "#perform max pooling\n",
    "#pool size of (2,2) to halve vertical and horizontal dimension of input\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#perform this bundle of convolutions, activation and max pooling again\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#activation and max pooling again\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#flatten layers out\n",
    "model.add(Flatten())\n",
    "#create a dense layer of 32 neurons\n",
    "model.add(Dense(32))\n",
    "#perform relu\n",
    "model.add(Activation('relu'))\n",
    "#perform dropout of 0.5\n",
    "#dropout will randomly swith neurons on and off\n",
    "#with a 0.5 chance to minimize overfitting\n",
    "model.add(Dropout(0.5))\n",
    "#finish off with one output unit..\n",
    "model.add(Dense(1))\n",
    "#..the sigmoid function will act as a logistic function:\n",
    "# a prediction as to 1 will predict its a dog\n",
    "# and a prediction as to 0 will predict its a cat.\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#lets configure the model for training:\n",
    "#choose binary_crossentropy as loss-function:\n",
    "#we have a binary classification problem\n",
    "#for keras optimizer choose 'rmsprop',\n",
    "#other optimizers e.g. 'adam' work well too\n",
    "#activate metrics so training can be overlooked\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n100/100 [==============================] - 26s 259ms/step - loss: 0.6976 - accuracy: 0.4985 - val_loss: 0.6934 - val_accuracy: 0.6050\nEpoch 2/20\n100/100 [==============================] - 26s 257ms/step - loss: 0.6937 - accuracy: 0.5335 - val_loss: 0.6881 - val_accuracy: 0.5075\nEpoch 3/20\n100/100 [==============================] - 26s 260ms/step - loss: 0.6873 - accuracy: 0.5715 - val_loss: 0.6770 - val_accuracy: 0.6212\nEpoch 4/20\n100/100 [==============================] - 29s 292ms/step - loss: 0.6651 - accuracy: 0.6235 - val_loss: 0.6674 - val_accuracy: 0.6400\nEpoch 5/20\n100/100 [==============================] - 31s 315ms/step - loss: 0.6296 - accuracy: 0.6495 - val_loss: 0.6661 - val_accuracy: 0.6800\nEpoch 6/20\n100/100 [==============================] - 30s 295ms/step - loss: 0.6045 - accuracy: 0.6645 - val_loss: 0.6406 - val_accuracy: 0.6850\nEpoch 7/20\n100/100 [==============================] - 34s 340ms/step - loss: 0.5689 - accuracy: 0.7085 - val_loss: 0.5743 - val_accuracy: 0.6800\nEpoch 8/20\n100/100 [==============================] - 31s 307ms/step - loss: 0.5518 - accuracy: 0.7185 - val_loss: 0.4789 - val_accuracy: 0.6062\nEpoch 9/20\n100/100 [==============================] - 27s 273ms/step - loss: 0.5340 - accuracy: 0.7350 - val_loss: 0.5173 - val_accuracy: 0.6988\nEpoch 10/20\n100/100 [==============================] - 27s 270ms/step - loss: 0.5125 - accuracy: 0.7450 - val_loss: 0.7595 - val_accuracy: 0.7125\nEpoch 11/20\n100/100 [==============================] - 29s 287ms/step - loss: 0.4898 - accuracy: 0.7640 - val_loss: 0.4146 - val_accuracy: 0.7088\nEpoch 12/20\n100/100 [==============================] - 31s 308ms/step - loss: 0.4677 - accuracy: 0.7800 - val_loss: 0.5253 - val_accuracy: 0.7050\nEpoch 13/20\n100/100 [==============================] - 27s 265ms/step - loss: 0.4502 - accuracy: 0.7930 - val_loss: 0.5770 - val_accuracy: 0.7113\nEpoch 14/20\n100/100 [==============================] - 27s 269ms/step - loss: 0.4292 - accuracy: 0.7970 - val_loss: 0.3894 - val_accuracy: 0.6700\nEpoch 15/20\n100/100 [==============================] - 28s 280ms/step - loss: 0.4165 - accuracy: 0.8155 - val_loss: 0.7330 - val_accuracy: 0.7138\nEpoch 16/20\n100/100 [==============================] - 31s 314ms/step - loss: 0.3972 - accuracy: 0.8155 - val_loss: 0.5658 - val_accuracy: 0.7075\nEpoch 17/20\n100/100 [==============================] - 29s 286ms/step - loss: 0.3755 - accuracy: 0.8275 - val_loss: 0.6178 - val_accuracy: 0.7325\nEpoch 18/20\n100/100 [==============================] - 27s 270ms/step - loss: 0.3834 - accuracy: 0.8295 - val_loss: 0.7147 - val_accuracy: 0.7163\nEpoch 19/20\n100/100 [==============================] - 26s 263ms/step - loss: 0.3457 - accuracy: 0.8430 - val_loss: 0.6813 - val_accuracy: 0.7163\nEpoch 20/20\n100/100 [==============================] - 26s 258ms/step - loss: 0.3353 - accuracy: 0.8470 - val_loss: 0.4423 - val_accuracy: 0.7412\n"
    }
   ],
   "source": [
    "#For large data sets like this one, use model.fit_generator\n",
    "model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    #total number of steps between two epochs:\n",
    "    #set to (nb_train_samples / batch_size) and round off\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "#once training is done, save the whole model incl. architecture, weights etc.\n",
    "model.save('CNN_model.h5')\n",
    "\n",
    "#Go to predict.ipynb to use this trained CNN to predict dog vs. cat images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}